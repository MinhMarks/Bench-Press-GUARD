# üìä T·ªïng H·ª£p C√¥ng Ngh·ªá Dataset - Bench Press Guard

## T·ªïng Quan

Project **Bench Press Guard** s·ª≠ d·ª•ng c√°c c√¥ng ngh·ªá x·ª≠ l√Ω d·ªØ li·ªáu real-time ƒë·ªÉ ph√°t hi·ªán nguy hi·ªÉm trong b√†i t·∫≠p Bench Press. Document n√†y t·ªïng h·ª£p t·∫•t c·∫£ c√°c c√¥ng ngh·ªá dataset ƒë∆∞·ª£c s·ª≠ d·ª•ng.

---

## 1. Ngu·ªìn D·ªØ Li·ªáu (Data Sources)

Project ho·∫°t ƒë·ªông v·ªõi **2 lo·∫°i input data** ch√≠nh:

### 1.1. Webcam Stream (Real-time)
- **C√¥ng ngh·ªá**: OpenCV `VideoCapture`
- **Resolution**: 1920x1080 (2MP)
- **Hardware FPS**: 30 FPS
- **Processing FPS**: 20 FPS (throttled)
- **Implementation**: Multi-threaded streaming qua `CameraStream` class

**ƒê·∫∑c ƒëi·ªÉm:**
```python
# Camera initialization
camera = CameraStream(src=0, width=1920, height=1080)
```

- S·ª≠ d·ª•ng threading ƒë·ªÉ tr√°nh blocking
- Real-time frame buffering
- Automatic latency monitoring

### 1.2. Video Files (Demo Mode)
- **Format h·ªó tr·ª£**: .mp4, .avi, v√† c√°c format video ph·ªï bi·∫øn
- **Auto FPS Detection**: T·ª± ƒë·ªông detect v√† match video FPS
- **Throttling**: Simulate real-time playback

**ƒê·∫∑c ƒëi·ªÉm:**
```python
# Video file mode
python main.py --video "demo_video.mp4"
```

- Frame-by-frame processing v·ªõi delay matching
- Kh√¥ng loop (stop khi h·∫øt video)
- S·ª≠ d·ª•ng c√πng pipeline nh∆∞ webcam

---

## 2. Feature Extraction (Tr√≠ch Xu·∫•t ƒê·∫∑c Tr∆∞ng)

### 2.1. MediaPipe Pose Estimation

**C√¥ng ngh·ªá core**: [Google MediaPipe Pose](https://google.github.io/mediapipe/solutions/pose.html)

**Model Configuration:**
```python
mp.solutions.pose.Pose(
    static_image_mode=False,
    model_complexity=1,              # Balanced speed/accuracy
    smooth_landmarks=True,            # Temporal smoothing
    min_detection_confidence=0.7,    # Detection threshold
    min_tracking_confidence=0.7      # Tracking threshold
)
```

**Output**: 33 body landmarks per frame

### 2.2. Landmark Data Structure

M·ªói frame ƒë∆∞·ª£c convert th√†nh **33 keypoints** v·ªõi format:

```python
{
    "id": 0-32,              # Landmark index
    "x_px": int,             # Pixel X coordinate
    "y_px": int,             # Pixel Y coordinate
    "x": 0.0-1.0,           # Normalized X (0-1)
    "y": 0.0-1.0,           # Normalized Y (0-1)
    "visibility": 0.0-1.0   # Confidence score
}
```

**Key Landmarks s·ª≠ d·ª•ng:**
- **ID 11**: Left Shoulder (vai tr√°i)
- **ID 12**: Right Shoulder (vai ph·∫£i)
- **ID 15**: Left Wrist (c·ªï tay tr√°i)
- **ID 16**: Right Wrist (c·ªï tay ph·∫£i)

---

## 3. Temporal Data Storage (L∆∞u Tr·ªØ D·ªØ Li·ªáu Th·ªùi Gian)

### 3.1. Time-Series Buffer

**C·∫•u tr√∫c**: `collections.deque` (double-ended queue)

**Configuration:**
```python
BUFFER_SIZE_SEC = 10  # L∆∞u 10 gi√¢y data history
TARGET_FPS = 20       # 20 frames/second
# => Buffer capacity: 200 frames
```

**D·ªØ li·ªáu l∆∞u tr·ªØ:**
- Barbell position history (x, y coordinates)
- Velocity time-series
- Tilt angle history
- Stability metrics over time

**M·ª•c ƒë√≠ch:**
- Ph√°t hi·ªán stall (barbell kh√¥ng di chuy·ªÉn)
- T√≠nh velocity/acceleration
- Temporal smoothing
- State transition logic

### 3.2. Event Logging (CSV Dataset)

**File output**: `bench_press_log.csv`

**Schema:**
```csv
Timestamp,BenchID,State,Reason,Latency_ms
2026-01-21T07:30:15.123456,1,DANGER,Stalled Barbell,45
2026-01-21T07:30:20.654321,1,NORMAL,Resumed Movement,42
```

**Columns:**
- `Timestamp`: ISO 8601 format (datetime.now().isoformat())
- `BenchID`: Bench station identifier (h·ªó tr·ª£ multi-bench)
- `State`: NORMAL | DANGER
- `Reason`: Chi ti·∫øt (Stalled Barbell, Tilt Detected, Uncontrolled Drop, etc.)
- `Latency_ms`: System processing latency

**·ª®ng d·ª•ng dataset:**
- Performance analysis
- Model evaluation metrics
- System monitoring
- Research dataset cho ML models

---

## 4. Region of Interest (ROI) Management

### 4.1. Interactive ROI Selection

**C√¥ng ngh·ªá**: OpenCV `cv2.selectROI()`

**Workflow:**
1. Hi·ªÉn th·ªã first frame
2. User v·∫Ω bounding box quanh bench area
3. Convert sang normalized coordinates (0-1)
4. L∆∞u tr·ªØ trong config

**Data Structure:**
```python
selected_roi = {
    "x": 0.0-1.0,  # Normalized X position
    "y": 0.0-1.0,  # Normalized Y position
    "w": 0.0-1.0,  # Normalized width
    "h": 0.0-1.0   # Normalized height
}
```

**L·ª£i √≠ch:**
- Scale-independent (ho·∫°t ƒë·ªông v·ªõi m·ªçi resolution)
- T·ªëi ∆∞u performance (ch·ªâ process ROI)
- Multi-bench support

### 4.2. Multi-Bench Architecture

**Data Structure:**
```python
benches = [
    {
        "id": 1,
        "roi": {"x": 0.2, "y": 0.1, "w": 0.6, "h": 0.8},
        "analyzer": BenchPressAnalyzer(fps=20)
    },
    # C√≥ th·ªÉ th√™m nhi·ªÅu benches...
]
```

**Scalability**: Architecture s·∫µn s√†ng cho multi-camera, multi-bench deployment

---

## 5. Derived Features (ƒê·∫∑c Tr∆∞ng T√≠nh To√°n)

T·ª´ raw landmarks, system t√≠nh to√°n c√°c physics features:

### 5.1. Barbell Physics

**Input**: Wrist landmarks (ID 15, 16)

**Output Features:**

#### a) Position
```python
midpoint_x = (left_wrist.x + right_wrist.x) / 2
midpoint_y = (left_wrist.y + right_wrist.y) / 2
```

#### b) Tilt Angle
```python
dx = right_wrist.x - left_wrist.x
dy = right_wrist.y - left_wrist.y
tilt_angle = atan2(dy, dx) * 180 / œÄ
```

#### c) Velocity
```python
# Computed from position buffer
velocity_y = (current_y - previous_y) / delta_time
```

#### d) Stability (Shake Detection)
```python
shoulder_width = distance(left_shoulder, right_shoulder)
lateral_movement = horizontal_variance(barbell_positions)
shake_percentage = lateral_movement / shoulder_width
```

### 5.2. Detection Thresholds

**Configuration** (t·ª´ `config.py`):

```python
# Th·ªùi gian
DANGER_STALL_TIME = 5.0           # Barbell kh√¥ng di chuy·ªÉn (seconds)
DANGER_LONG_BOTTOM_TIME = 7.0     # N·∫±m qu√° l√¢u ·ªü bottom (seconds)

# V·∫≠t l√Ω
DANGER_TILT_ANGLE = 20.0          # ƒê·ªô nghi√™ng nguy hi·ªÉm (degrees)
DANGER_SHAKE_PCT = 0.10           # 10% shoulder width
DANGER_DROP_VELOCITY_THRESHOLD = 0.8  # Relative velocity

# H·ªá th·ªëng
MAX_LATENCY_SEC = 0.5             # Maximum acceptable latency
STATE_CONSISTENCY_WINDOW = 0.5    # Anti-flicker window
```

---

## 6. Data Processing Pipeline

```mermaid
graph TB
    A[Video/Camera Source] --> B[Frame Capture<br/>1920x1080 @ 20 FPS]
    B --> C[ROI Extraction<br/>User-defined region]
    C --> D[MediaPipe Pose<br/>33 Landmarks]
    D --> E[Barbell Extraction<br/>Wrists ID 15, 16]
    E --> F[Physics Calculation<br/>Position, Tilt, Velocity]
    F --> G[Temporal Buffer<br/>10s history deque]
    G --> H[State Analyzer<br/>NORMAL/DANGER FSM]
    H --> I[CSV Logger<br/>bench_press_log.csv]
    H --> J[Visual Dashboard<br/>Real-time overlay]
```

### Pipeline Chi Ti·∫øt

**Step 1: Frame Acquisition**
- Source: Webcam (threaded) ho·∫∑c Video file (throttled)
- Resolution: 1920x1080
- Rate: 20 FPS processing

**Step 2: ROI Processing**
- Extract sub-image d·ª±a tr√™n normalized ROI
- Clamping ƒë·ªÉ avoid out-of-bounds

**Step 3: Pose Detection**
- MediaPipe inference (~30-50ms per frame)
- 33 landmarks v·ªõi visibility scores

**Step 4: Feature Engineering**
- Barbell position t·ª´ wrists
- Shoulder width reference
- Physics calculations

**Step 5: Temporal Analysis**
- Append to 10s deque buffer
- Velocity calculation t·ª´ position deltas
- Stall detection t·ª´ movement history

**Step 6: State Machine**
- Finite State Machine (FSM)
- States: NORMAL, DANGER
- Transitions based on threshold violations

**Step 7: Output**
- Console logging (color-coded)
- CSV file append
- Visual overlay rendering

---

## 7. Technology Stack

### 7.1. Core Dependencies

```txt
opencv-python      # Video I/O, image processing, ROI selection
mediapipe          # Pre-trained pose estimation model
numpy              # Numerical computations, array operations
```

### 7.2. Standard Library Usage

- `threading`: Multi-threaded camera stream
- `collections.deque`: Efficient FIFO buffer
- `csv`: Structured logging
- `datetime`: Timestamp generation
- `argparse`: CLI argument parsing

### 7.3. Kh√¥ng S·ª≠ D·ª•ng

‚ùå Pre-collected datasets (COCO, MPII, etc.)  
‚ùå Training/Fine-tuning workflows  
‚ùå Deep learning frameworks (TensorFlow/PyTorch)  
‚ùå Cloud APIs ho·∫∑c external services  
‚ùå Database systems (SQLite, PostgreSQL, etc.)

**L√Ω do**: Project focus v√†o real-time inference v·ªõi pre-trained model, kh√¥ng c·∫ßn training infrastructure.

---

## 8. Data Flow Characteristics

### 8.1. Input Data

| Aspect | Specification |
|--------|---------------|
| **Type** | Video stream (live/file) |
| **Resolution** | 1920x1080 pixels |
| **Color Space** | BGR ‚Üí RGB conversion |
| **Frame Rate** | 20 FPS (processing) |
| **ROI Size** | User-defined, typically 60% of frame |

### 8.2. Intermediate Data

| Layer | Data Structure | Size |
|-------|----------------|------|
| **Raw Landmarks** | List[Dict] √ó 33 | ~2 KB/frame |
| **Barbell State** | Dict (position, angle, velocity) | ~0.5 KB/frame |
| **Temporal Buffer** | Deque[200 frames] | ~500 KB total |

### 8.3. Output Data

| Output | Format | Update Rate |
|--------|--------|-------------|
| **CSV Log** | Append-only file | Per state change |
| **Console** | ANSI colored text | Per state change |
| **Visual Overlay** | OpenCV rendering | 20 FPS |

---

## 9. Performance Metrics

### 9.1. System Latency

**Tracked Metrics:**
```python
latency = current_time - last_frame_time
```

- Target: < 50ms per frame
- Logged in CSV cho analysis
- Monitored real-time trong dashboard

### 9.2. Processing Breakdown

| Stage | Approximate Time |
|-------|------------------|
| Frame capture | 5-10ms |
| MediaPipe inference | 30-50ms |
| Feature extraction | 1-2ms |
| State analysis | 1-2ms |
| Visualization | 5-10ms |
| **Total** | **~50-75ms** |

**Achievable FPS**: ~13-20 FPS (meets 20 FPS target)

---

## 10. Dataset Use Cases

### 10.1. Generated Dataset (`bench_press_log.csv`)

**·ª®ng d·ª•ng:**

1. **Performance Analysis**
   - Failure rate statistics
   - Time-to-detection metrics
   - False positive/negative analysis

2. **Model Evaluation**
   - Precision/Recall calculations
   - Confusion matrix generation
   - Threshold tuning validation

3. **System Monitoring**
   - Latency trend analysis
   - Uptime tracking
   - Multi-bench comparison

4. **Research Applications**
   - Training data cho ML enhancement
   - Benchmark dataset cho new algorithms
   - Case study documentation

### 10.2. Potential Extensions

**Future Dataset Integration:**

- **Video Dataset**: Record dangerous events cho visual analysis
- **Annotation Tool**: Manual labeling interface cho ground truth
- **Synthetic Data**: Simulated failures cho edge case testing
- **Transfer Learning**: Fine-tune MediaPipe tr√™n bench press specific poses

---

## 11. ƒêi·ªÉm ƒê·∫∑c Bi·ªát c·ªßa Ki·∫øn Tr√∫c Dataset

### ‚úÖ Advantages

1. **Real-time Processing**
   - Kh√¥ng c·∫ßn offline dataset
   - Zero training time
   - Immediate deployment

2. **Lightweight Architecture**
   - Ch·ªâ c·∫ßn 3 dependencies
   - Pre-trained model (kh√¥ng train)
   - Ch·∫°y ƒë∆∞·ª£c tr√™n CPU

3. **Self-Documenting**
   - T·ª± generate CSV dataset t·ª´ detections
   - Timestamp ch√≠nh x√°c
   - Structured logging

4. **Domain-Specific Optimization**
   - T·ªëi ∆∞u cho bench press detection
   - Custom physics features
   - Specific threshold tuning

5. **Scalable Design**
   - Multi-bench ready
   - Normalized coordinates
   - Configurable thresholds

### üîç Design Decisions

1. **T·∫°i sao kh√¥ng d√πng training datasets?**
   - MediaPipe ƒë√£ pre-trained tr√™n COCO/MPII
   - Kh√¥ng c·∫ßn domain-specific training
   - Focus v√†o inference performance

2. **T·∫°i sao d√πng CSV thay v√¨ database?**
   - Simplicity: Easy to read/parse
   - Portability: No DB setup required
   - Lightweight: Append-only operations

3. **T·∫°i sao buffer 10 gi√¢y?**
   - Balance memory vs. temporal analysis
   - ƒê·ªß ƒë·ªÉ detect stalls (5s threshold)
   - Fit trong RAM (~500 KB)

---

## 12. K·∫øt Lu·∫≠n

Project **Bench Press Guard** s·ª≠ d·ª•ng m·ªôt ki·∫øn tr√∫c dataset **real-time, lightweight, v√† practical**:

- **Input**: Video streams (live/file)
- **Processing**: MediaPipe pose ‚Üí physics features ‚Üí temporal analysis
- **Output**: Structured CSV logs + real-time alerts

ƒêi·ªÉm m·∫°nh ch√≠nh l√† **kh√¥ng c·∫ßn training infrastructure** nh∆∞ng v·∫´n ƒë·∫°t high accuracy nh·ªù domain-specific feature engineering v√† threshold tuning.

Dataset sinh ra (`bench_press_log.csv`) c√≥ th·ªÉ serve nh∆∞ foundation cho future ML enhancements v√† research applications.

---

## üìö T√†i Li·ªáu Tham Kh·∫£o

- [MediaPipe Pose Documentation](https://google.github.io/mediapipe/solutions/pose.html)
- [OpenCV VideoCapture API](https://docs.opencv.org/4.x/d8/dfe/classcv_1_1VideoCapture.html)
- Project Files:
  - [core/camera.py](file:///d:/UIT/Webdev/GymerGaurd/core/camera.py) - Video streaming
  - [core/detector.py](file:///d:/UIT/Webdev/GymerGaurd/core/detector.py) - Pose detection
  - [core/logger.py](file:///d:/UIT/Webdev/GymerGaurd/core/logger.py) - CSV logging
  - [config.py](file:///d:/UIT/Webdev/GymerGaurd/config.py) - Thresholds v√† constants
